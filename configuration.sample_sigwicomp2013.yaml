general:
  random_seed: 100
  split_count: 0
  train_writer_count: 11
  reference_sample_count: 12
  classification_report_digits: 4
  directory_template: "b{ct}-{earc}-{darc}-{epc}"
  output_directory_template: "./models/{dir}"

logger:
  log_format: "(%(asctime)s) %(name)s [%(levelname)s]: %(message)s"
  log_file: "./models/{dir}/seq2seq.log"
  log_level: "info"

export:
  evaluation:
    - "Precision"
    - "Recall"
    - "F1"

data:
  reading:
    writer_count: 31
    genuine_sample_count: 42
    forged_sample_count: 36
    dataset_path: "./datasets/sigwicomp2013.npz"

  reshaping:
    features: 14
    sampling_step: 5
    window_size: 1
    window_step: 1
    length_threshold: 10000

siamese:
  mode: "train"
  train:
    batch_size: 128
    epochs: 1000
    workers: 16
    use_multiprocessing: true
    verbose: 1

  test:
    probability_threshold: 0.5
    accept_threshold: 6

  compile_config:
    loss: "binary_crossentropy"
    optimizer:
      name: "adam"
      args: {}
    metrics:
      - "acc"

  callbacks:
    early_stopping:
      monitor: "loss"
      patience: 10
      verbose: 1

  architecture:
    global: &siamese
      activation: "relu"
      dropout: 0.45

    before:
      0:
        <<: *siamese
        dropout: 0.0
        units: 250

    after:
      0:
        <<: *siamese
        units: 75

  merge_mode: 'subtract'

autoencoder:
  mode: "train"
  train:
    batch_size: 128
    epochs: 1000
    workers: 16
    use_multiprocessing: true
    verbose: 1

  compile_config:
    loss: "mape"
    optimizer:
      name: "adam"
      args: {}
    metrics:
      - "mae"
      - "mse"

  callbacks:
    early_stopping:
      monitor: "loss"
      patience: 10
      verbose: 1

  architecture:
    global: &autoencoder
      return_sequences: true
      implementation: 2
      activation: "relu"
      dropout: 0.5
      merge_mode: "concat"

    encoder:
      0:
        <<: *autoencoder
        go_backwards: true
        dropout: 0.0
        units: 100
      1:
        <<: *autoencoder
        units: 150

    decoder:
      0:
        <<: *autoencoder
        dropout: 0.0
        units: 100
      1:
        <<: *autoencoder
        merge_mode: "ave"
        units: 14

    cell_type: "LSTM"
